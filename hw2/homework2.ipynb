{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "In this assignment, we will be exploring the car dataset and analyzing their fuel efficiency again. <br >\n",
    "Specifically, this time we will do more data understanding and build one Logistic Regression model. <br >\n",
    "**The given dataset is already modified and cleaned**, but you can find [the original information here.](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n",
    "\n",
    "### Dataset Attribute Information\n",
    "\n",
    "1. **mpg**: Miles per gallon. This is one primary measurement for car fuel efficiency.\n",
    "2. **displacement** : The cylinder volumes in cubic inches.\n",
    "3. **horsepower** : Engine power.\n",
    "4. **weight** : In pounds.\n",
    "5. **acceleration** : The elapsed time in seconds to go from 0 to 60mph.\n",
    "6. **origin** : Region of origin.\n",
    "\n",
    "Moving to the second part of this assignment we want to get deeper into polinomial regression, where we want use the dataset 'cost.csv' to analysis tthe relationship between production output and cost.\n",
    "\n",
    "\n",
    "#### Libraries that could possiblly be used: numpy, scipy, pandas, scikit-learn, matplotlib, operator\n",
    "\n",
    "#### Other Notes\n",
    " - Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of **this** assignment. <br >\n",
    " - If not specified, you are not required to do hyperparameter tuning, but feel free to do so if you'd like.\n",
    " - Discussion materials should be helpful for doing the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 : Data Understanding (20 points in total)\n",
    "Recall the dataset 'auto-mpg.csv' from last week homework, we are goint to use it again for Exercise 1 and 2 again.\n",
    "* As the classes(``origin``) are categorical, use one-hot encoding to represent the set of classes. \n",
    "* Normalize each field of the input data using the min-max normalization technique.\n",
    "* Plot the distribution of data and analyze the distribution. Explain if the data is symmetric, or sekewed to right or left. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Logistic Regression (20 points in total)\n",
    "Now we are going to build a classification model on ``origin`` using all the other 5 attributes. <br >\n",
    "Note that Logistic Regression is a binary classificaiton algorithm.\n",
    "\n",
    "### Exercise 2.1 - Processing and Splitting the Dataset (5 points)\n",
    "In this exercise 1, we only consider those observations where they originate from either \"USA\" or \"Japan\". <br >\n",
    "So please **remove** those observations that originate from \"Europe\". <br >\n",
    "And then, split the data into training and testing set with the ratio of 80:20. <br >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - Logistic Regression (15 points)\n",
    "\n",
    "Using all the other 5 attributes, please build a Logistic Regression model that distinguishes between cars from Japan and cars from the USA. <br >\n",
    "Then, **if we are distinguishing between Japan and Europe this time, how do you think the model performance(in terms of accuracy) will change? Provide your reasoning.** (Hint: Exercise 1)\n",
    "\n",
    "Requirements\n",
    " - Report the testing precision and recall for both regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Polynomial Regressor using Gradient Descent (25 points in total)\n",
    "Now we are going to look into model fitting. In the dataset 'cost.csv', the first column is the independent variable production_output, and the second column is the dependent variable cost.\n",
    "\n",
    "### Exercise 3.1 - Split the dataset (5 points)\n",
    "Import the dataset 'cost.csv' and split them into training and testing set with ratio 70:30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - Polynomial Regression (20 points)\n",
    "Compute the RMSE and R2 for the training and testing set. Using polynomial regression with degree 1, 2, 3, and 4, which model provides the most appropriate prediction? Justify your answer and plot the fitted line for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 : Log Likelihood (35 points in total)\n",
    "For a model with two independent variables x1 (Weight) and x2 (Length), compute the log-likelihood for the model: ŷ = 0.1 x1 + 0.1 x2 , where the dependent variable ŷ represents the prediction for Height. Given the dataset below (in the table), assuming that the measurements have normal distribution, please complete the table by calculating the Pridicted hight, squared residual and log-likelihood for each data point. Then, compute and report the log-likelihood for the entire dataset. \n",
    "\n",
    "Round your answer to 4 d.p. For simplicity, use and log base 10.\n",
    "\n",
    "Hint: $f(y_i)=\\frac{1}{\\sqrt{2\\piσ^2}}e^{\\frac{-(y_i-ŷ_i)^2}{2σ^2}}$\n",
    "\n",
    "Model M1: \n",
    "Weight x1 | Length x2 | Actual Height y | Predicted Height ŷ | squared residual (y - ŷ )^2 | Log-Likelihood\n",
    "---|---|---|---|---|---|\n",
    "7.0 | 50 | 5.80\n",
    "6.0 | 55 | 5.70\n",
    "8.0 | 56 | 6.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
